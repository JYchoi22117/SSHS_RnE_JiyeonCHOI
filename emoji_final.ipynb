{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1765edd48844c7a9533901d64af9732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b561d4cc08e7445892c44fcde18b9028",
              "IPY_MODEL_d0231dd36cde4268a6f995b2307faaa4",
              "IPY_MODEL_fb8324f2f42641cb878b6eced60f3b22"
            ],
            "layout": "IPY_MODEL_79e9a14dab5045b792377a9a0efff660"
          }
        },
        "b561d4cc08e7445892c44fcde18b9028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_349fc97c817d474bac2ad70219090252",
            "placeholder": "​",
            "style": "IPY_MODEL_374965fc68b04bf69881109088561015",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "d0231dd36cde4268a6f995b2307faaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7916a1b4d3ab49729c1a402b22028a2f",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51334c25d0874a32b317bddb80f3bdc5",
            "value": 2825034
          }
        },
        "fb8324f2f42641cb878b6eced60f3b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7969b34914534556a70eb15d59d7d38e",
            "placeholder": "​",
            "style": "IPY_MODEL_86ed55aa260a4c3cbc8abbe4de3c7d54",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 20.2MB/s]"
          }
        },
        "79e9a14dab5045b792377a9a0efff660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349fc97c817d474bac2ad70219090252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "374965fc68b04bf69881109088561015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7916a1b4d3ab49729c1a402b22028a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51334c25d0874a32b317bddb80f3bdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7969b34914534556a70eb15d59d7d38e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ed55aa260a4c3cbc8abbe4de3c7d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d0d6114347478bb2b615ed49fd0bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5057cf94828f45528db310475ab9f68f",
              "IPY_MODEL_c5997c31031f4402b612c507f5961e2d",
              "IPY_MODEL_126cc74d54de4cec83a252db2cd8298a"
            ],
            "layout": "IPY_MODEL_595a89ea7608442bba50f8cb44950862"
          }
        },
        "5057cf94828f45528db310475ab9f68f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c4c5cc9bba420d86d5a3e96976930b",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9fb8991314458a8b1e770127d98efc",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c5997c31031f4402b612c507f5961e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4ab3c32c3d448aaa214c3cb1fde035",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85131835a3c3407db23b631c27a22eb5",
            "value": 1000
          }
        },
        "126cc74d54de4cec83a252db2cd8298a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b9b8738c2ac4f0a861ee5f12f6aafee",
            "placeholder": "​",
            "style": "IPY_MODEL_753301223bcf49d1b8394e62c2da5396",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 42.6kB/s]"
          }
        },
        "595a89ea7608442bba50f8cb44950862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c4c5cc9bba420d86d5a3e96976930b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9fb8991314458a8b1e770127d98efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4ab3c32c3d448aaa214c3cb1fde035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85131835a3c3407db23b631c27a22eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b9b8738c2ac4f0a861ee5f12f6aafee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753301223bcf49d1b8394e62c2da5396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d3b6d981e084cdbb66ab4343691dcdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c47561ab415f4eadac2c955820c94621",
              "IPY_MODEL_274b576c66584474aa5a9c7437ed4ccf",
              "IPY_MODEL_a31625adf39348bbbd7eb6d18efb05a8"
            ],
            "layout": "IPY_MODEL_0904a99a09124e64bfc125fdd5d7d1fe"
          }
        },
        "c47561ab415f4eadac2c955820c94621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706a0bb8dc3f4802ac46588b4e0ec8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_460f88269d75459b96b87188a497af5a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "274b576c66584474aa5a9c7437ed4ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_839604d5bf2c4cb8801bb2d08c32729e",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_493945bbea694cc089238c8f90db1c34",
            "value": 513302779
          }
        },
        "a31625adf39348bbbd7eb6d18efb05a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09159ad8574a43a9a19bd580115cc504",
            "placeholder": "​",
            "style": "IPY_MODEL_e859b77c5b5c4e8b9d7ad7f44efec052",
            "value": " 513M/513M [00:16&lt;00:00, 37.9MB/s]"
          }
        },
        "0904a99a09124e64bfc125fdd5d7d1fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "706a0bb8dc3f4802ac46588b4e0ec8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460f88269d75459b96b87188a497af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "839604d5bf2c4cb8801bb2d08c32729e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "493945bbea694cc089238c8f90db1c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09159ad8574a43a9a19bd580115cc504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e859b77c5b5c4e8b9d7ad7f44efec052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JYchoi22117/SSHS_RnE_JiyeonCHOI/blob/main/emoji_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODndnW_3pt7p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwTrjdjTn3R-",
        "outputId": "d502b4fe-2e5b-417e-8103-d12e4b447dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsW1bHGjgWPg",
        "outputId": "0ab7bd4d-f592-464b-b1d1-eff185de99f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Found existing installation: pytorch-lightning 2.0.9\n",
            "Uninstalling pytorch-lightning-2.0.9:\n",
            "  Successfully uninstalled pytorch-lightning-2.0.9\n",
            "Collecting pytorch-lightning\n",
            "  Using cached pytorch_lightning-2.0.9-py3-none-any.whl (727 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.1.2)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: pytorch-lightning\n",
            "Successfully installed pytorch-lightning-2.0.9\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2023.7.22)\n",
            "Requirement already satisfied: gluonnlp==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-s61jegp5/kobert-tokenizer_d3c2bd1b257a47ffb3d9d2ca1d0eb81c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-s61jegp5/kobert-tokenizer_d3c2bd1b257a47ffb3d9d2ca1d0eb81c\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/SKTBrain/KoBERT.git\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-req-build-dqa4nhiz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-req-build-dqa4nhiz\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3<=1.15.18 (from kobert==0.2.3)\n",
            "  Using cached boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from kobert==0.2.3) (0.8.0)\n",
            "Collecting mxnet<=1.7.0.post2,>=1.4.0 (from kobert==0.2.3)\n",
            "  Using cached mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "INFO: pip is looking at multiple versions of kobert to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime<=1.8.0,==1.8.0 (from kobert) (from versions: 1.12.0, 1.12.1, 1.13.1, 1.14.0, 1.14.1, 1.15.0, 1.15.1, 1.16.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime<=1.8.0,==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: kobert-transformers in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (4.33.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->kobert-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.1.0->kobert-transformers) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5,>=3->kobert-transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers<5,>=3->kobert-transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->kobert-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->kobert-transformers) (1.3.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.28.51)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.51 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.31.51)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.51->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.51->boto3) (1.26.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.51->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#KoGPT2\n",
        "#모듈 설치\n",
        "\n",
        "!pip install --upgrade transformers\n",
        "!pip uninstall -y pytorch-lightning\n",
        "!pip install pytorch-lightning\n",
        "\n",
        "#KoBERT\n",
        "#모듈 설치\n",
        "\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp==0.8.0\n",
        "!pip install pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf' #허깅페이스\n",
        "!pip install git+https://github.com/SKTBrain/KoBERT.git\n",
        "!pip3 install kobert-transformers\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-XN8Y4_h9XU"
      },
      "source": [
        "런타임 다시 시작"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwdMfRrXZcy9"
      },
      "source": [
        "# **KoGPT2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEZGaAOpRKmB"
      },
      "source": [
        "data 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "0cLRxClxQ3Ej",
        "outputId": "9cb9a6f9-19fe-41dd-ee38-b4cedb6e3257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-8c4b430792f1>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  wellness.rename(columns = {'utterance(2차) ' : 'utterance'}, inplace = True)\n",
            "<ipython-input-9-8c4b430792f1>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  wellness.rename(columns = {'response(공감)' : 'response'}, inplace = True)\n",
            "<ipython-input-9-8c4b430792f1>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  songys.rename(columns = {'Q' : 'utterance'}, inplace = True)\n",
            "<ipython-input-9-8c4b430792f1>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  songys.rename(columns = {'A' : 'response'}, inplace = True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       utterance  \\\n",
              "0                       임신해서 우울해   \n",
              "1                  아이 가지고 나서 우울해   \n",
              "2        아이 가졌는데 기분 하나도 안 좋고 울적해   \n",
              "3      임신했는데 남편이 하나도 안 챙겨줘서 우울하다   \n",
              "1657                     노산이라 슬퍼   \n",
              "...                          ...   \n",
              "11818             훔쳐보는 것도 눈치 보임.   \n",
              "11819             훔쳐보는 것도 눈치 보임.   \n",
              "11820                흑기사 해주는 짝남.   \n",
              "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?   \n",
              "11822                 힘들어서 결혼할까봐   \n",
              "\n",
              "                                                response  \n",
              "0         기분이 우울하시군요. 00님에게 스트레스 받는 일이 있었던 건 아닌지 걱정스러워요.  \n",
              "1         마음이 우울해서 힘드셨군요. 00님의 소식이 궁금했는데 마침 저를 잘 찾아주셨네요.  \n",
              "2                              00님이 울적하시다니 저도 마음이 안 좋아요.  \n",
              "3      얼굴에서 00님의 기분이 가라앉은 것이 느껴져요. 큰일이 있으신 건 아니었으면 좋겠어요.  \n",
              "1657   00님 속상한 일이 있으셨나 봐요. 저와 이야기를 하며 조금은 기분이 나아지셨으면 ...  \n",
              "...                                                  ...  \n",
              "11818                                 티가 나니까 눈치가 보이는 거죠!  \n",
              "11819                                      훔쳐보는 거 티나나봐요.  \n",
              "11820                                             설렜겠어요.  \n",
              "11821                           잘 헤어질 수 있는 사이 여부인 거 같아요.  \n",
              "11822                                 도피성 결혼은 하지 않길 바라요.  \n",
              "\n",
              "[11897 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-373e8beb-6877-4241-b79e-50137fb4e0f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>임신해서 우울해</td>\n",
              "      <td>기분이 우울하시군요. 00님에게 스트레스 받는 일이 있었던 건 아닌지 걱정스러워요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>아이 가지고 나서 우울해</td>\n",
              "      <td>마음이 우울해서 힘드셨군요. 00님의 소식이 궁금했는데 마침 저를 잘 찾아주셨네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>아이 가졌는데 기분 하나도 안 좋고 울적해</td>\n",
              "      <td>00님이 울적하시다니 저도 마음이 안 좋아요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>임신했는데 남편이 하나도 안 챙겨줘서 우울하다</td>\n",
              "      <td>얼굴에서 00님의 기분이 가라앉은 것이 느껴져요. 큰일이 있으신 건 아니었으면 좋겠어요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>노산이라 슬퍼</td>\n",
              "      <td>00님 속상한 일이 있으셨나 봐요. 저와 이야기를 하며 조금은 기분이 나아지셨으면 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11818</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11819</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>훔쳐보는 거 티나나봐요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11820</th>\n",
              "      <td>흑기사 해주는 짝남.</td>\n",
              "      <td>설렜겠어요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11821</th>\n",
              "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
              "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11822</th>\n",
              "      <td>힘들어서 결혼할까봐</td>\n",
              "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11897 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-373e8beb-6877-4241-b79e-50137fb4e0f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-373e8beb-6877-4241-b79e-50137fb4e0f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-373e8beb-6877-4241-b79e-50137fb4e0f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2eb4d1f9-39d1-48dc-8c89-b5763c376dba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2eb4d1f9-39d1-48dc-8c89-b5763c376dba')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2eb4d1f9-39d1-48dc-8c89-b5763c376dba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#데이터 불러오기\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "wellness = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/wellness.csv\", encoding = \"cp949\")\n",
        "songys = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/songys.csv\", encoding = \"cp949\")\n",
        "# corpus = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training.csv\")\n",
        "\n",
        "#corpus의 1,2,3 나눠서 csv 저장하기\n",
        "\n",
        "# corpus1 = corpus[['사람문장1', '시스템문장1']]\n",
        "# corpus1.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_1.csv\")\n",
        "# corpus2 = corpus[['사람문장2', '시스템문장2']]\n",
        "# corpus2.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_2.csv\")\n",
        "# corpus3 = corpus[['사람문장3', '시스템문장3']]\n",
        "# corpus3.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_3.csv\")\n",
        "\n",
        "#KoGPT2 학습을 위해 데이터 결합하기\n",
        "\n",
        "#1. wellness utterance와 response만 가지고 와서 열 이름 바꾸기, dropna\n",
        "wellness = wellness[['utterance(2차) ', 'response(공감)']]\n",
        "wellness.rename(columns = {'utterance(2차) ' : 'utterance'}, inplace = True)\n",
        "wellness.rename(columns = {'response(공감)' : 'response'}, inplace = True)\n",
        "wellness = wellness.dropna(axis=0)\n",
        "# wellness\n",
        "\n",
        "#2. songys q와 a만 가지고 오기, dropna\n",
        "songys = songys[['Q', 'A']]\n",
        "songys.rename(columns = {'Q' : 'utterance'}, inplace = True)\n",
        "songys.rename(columns = {'A' : 'response'}, inplace = True)\n",
        "songys = songys.dropna(axis=0)\n",
        "# songys\n",
        "\n",
        "# #3. corpus 3개 모두 불러와서 먼저 합치기, 열 이름 바꾸기, dropna\n",
        "# corpus1 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_1.csv\")\n",
        "# corpus1.rename(columns = {'사람문장1' : 'utterance'}, inplace = True)\n",
        "# corpus1.rename(columns = {'시스템문장1' : 'response'}, inplace = True)\n",
        "# corpus2 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_2.csv\")\n",
        "# corpus2.rename(columns = {'사람문장2' : 'utterance'}, inplace = True)\n",
        "# corpus2.rename(columns = {'시스템문장2' : 'response'}, inplace = True)\n",
        "# corpus3 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_3.csv\")\n",
        "# corpus3.rename(columns = {'사람문장3' : 'utterance'}, inplace = True)\n",
        "# corpus3.rename(columns = {'시스템문장3' : 'response'}, inplace = True)\n",
        "# corpus = pd.concat([corpus1, corpus2, corpus3], axis = 0)\n",
        "# corpus = corpus.dropna(axis=0)\n",
        "# # corpus\n",
        "\n",
        "# 4. 위 1,2,3번 데이터 프레임 합치기\n",
        "emoji_data = pd.concat([wellness, songys], axis = 0)\n",
        "# emoji_data = pd.concat([wellness, songys, corpus], axis = 0)\n",
        "# emoji_data.to_csv(\"/content/drive/MyDrive/연구/230824 emoji/dataset/emoji_data\") #필요 시 저장\n",
        "emoji_data\n",
        "\n",
        "#Unnamed:0 열 삭제하기\n",
        "\n",
        "emoji_data = emoji_data[['utterance', 'response']]\n",
        "emoji_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzwtJTXNV1A0"
      },
      "source": [
        "필요한 모듈 설치 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8f0dA_ugR86X"
      },
      "outputs": [],
      "source": [
        "#모듈 실행\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "#from pytorch_lightning.core.lightning import LightningModule #모듈 에러 발생해서 우선 보류\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import urllib.request\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PreTrainedTokenizerFast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQy870MKWdTo"
      },
      "source": [
        "토크나이저/모델 설정, 토큰 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "b1765edd48844c7a9533901d64af9732",
            "b561d4cc08e7445892c44fcde18b9028",
            "d0231dd36cde4268a6f995b2307faaa4",
            "fb8324f2f42641cb878b6eced60f3b22",
            "79e9a14dab5045b792377a9a0efff660",
            "349fc97c817d474bac2ad70219090252",
            "374965fc68b04bf69881109088561015",
            "7916a1b4d3ab49729c1a402b22028a2f",
            "51334c25d0874a32b317bddb80f3bdc5",
            "7969b34914534556a70eb15d59d7d38e",
            "86ed55aa260a4c3cbc8abbe4de3c7d54",
            "10d0d6114347478bb2b615ed49fd0bd3",
            "5057cf94828f45528db310475ab9f68f",
            "c5997c31031f4402b612c507f5961e2d",
            "126cc74d54de4cec83a252db2cd8298a",
            "595a89ea7608442bba50f8cb44950862",
            "88c4c5cc9bba420d86d5a3e96976930b",
            "2c9fb8991314458a8b1e770127d98efc",
            "7e4ab3c32c3d448aaa214c3cb1fde035",
            "85131835a3c3407db23b631c27a22eb5",
            "6b9b8738c2ac4f0a861ee5f12f6aafee",
            "753301223bcf49d1b8394e62c2da5396",
            "0d3b6d981e084cdbb66ab4343691dcdb",
            "c47561ab415f4eadac2c955820c94621",
            "274b576c66584474aa5a9c7437ed4ccf",
            "a31625adf39348bbbd7eb6d18efb05a8",
            "0904a99a09124e64bfc125fdd5d7d1fe",
            "706a0bb8dc3f4802ac46588b4e0ec8cb",
            "460f88269d75459b96b87188a497af5a",
            "839604d5bf2c4cb8801bb2d08c32729e",
            "493945bbea694cc089238c8f90db1c34",
            "09159ad8574a43a9a19bd580115cc504",
            "e859b77c5b5c4e8b9d7ad7f44efec052"
          ]
        },
        "id": "T90nj1JnWjyF",
        "outputId": "d30d691f-98f4-4274-a9b1-5438c033a71f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1765edd48844c7a9533901d64af9732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10d0d6114347478bb2b615ed49fd0bd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d3b6d981e084cdbb66ab4343691dcdb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#토큰 정의\n",
        "\n",
        "Q_TKN = \"<usr>\"\n",
        "A_TKN = \"<sys>\"\n",
        "BOS = '</s>'\n",
        "EOS = '</s>'\n",
        "MASK = '<unused0>'\n",
        "SENT = '<unused1>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "#토크나이저/모델 설정\n",
        "\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
        "            pad_token=PAD, mask_token=MASK)\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sna5PNLXPXw"
      },
      "source": [
        "클래스 정의 - 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UoVlkBILW4ml"
      },
      "outputs": [],
      "source": [
        "# chatbotdata 만드는 클래스 정의하기\n",
        "\n",
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, chats, max_len=50):  # 데이터셋의 전처리를 해주는 부분/max_len 100으로 늘려보기\n",
        "        self._data = chats\n",
        "        self.max_len = max_len\n",
        "        self.q_token = Q_TKN\n",
        "        self.a_token = A_TKN\n",
        "        self.sent_token = SENT\n",
        "        self.eos = EOS\n",
        "        self.mask = MASK\n",
        "        self.tokenizer = koGPT2_TOKENIZER\n",
        "\n",
        "    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n",
        "        turn = self._data.iloc[idx]\n",
        "        q = turn[\"utterance\"]  # 질문을 가져온다.\n",
        "        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n",
        "\n",
        "        a = turn[\"response\"]  # 답변을 가져온다.\n",
        "        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n",
        "\n",
        "        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n",
        "        q_len = len(q_toked)\n",
        "\n",
        "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "        a_len = len(a_toked)\n",
        "\n",
        "        #질문의 길이가 최대길이보다 크면\n",
        "        if q_len > self.max_len:\n",
        "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
        "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
        "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로\n",
        "                q_len = len(q_toked)\n",
        "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "\n",
        "        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n",
        "        if q_len + a_len > self.max_len:\n",
        "            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n",
        "            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n",
        "                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로\n",
        "                q_len = len(q_toked)\n",
        "                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "\n",
        "        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n",
        "        labels = [self.mask,] * q_len + a_toked[1:]\n",
        "\n",
        "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "        # 답변 labels을 index 로 만든다.\n",
        "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "        # 최대길이만큼 PADDING\n",
        "        while len(labels_ids) < self.max_len:\n",
        "            labels_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        # 질문 + 답변을 index 로 만든다.\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "        # 최대길이만큼 PADDING\n",
        "        while len(token_ids) < self.max_len:\n",
        "            token_ids += [self.tokenizer.pad_token_id]\n",
        "\n",
        "        #질문+답변, 마스크, 답변\n",
        "        return (token_ids, np.array(mask), labels_ids)\n",
        "\n",
        "#collate_batch 클래스 정의하기\n",
        "\n",
        "def collate_batch(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    mask = [item[1] for item in batch]\n",
        "    label = [item[2] for item in batch]\n",
        "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-QHHJU3XSVz",
        "outputId": "f4948fe8-c7c3-48df-811d-807cfa59929d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51200, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#학습세트 크기 정의하기\n",
        "\n",
        "train_set = ChatbotDataset(emoji_data, max_len=50)\n",
        "#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n",
        "train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)\n",
        "\n",
        "#cpu인지 아닌지 확인하는 코드\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#아래 코드 해석 못함\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jghiGhBAYBIr",
        "outputId": "0e33d9ef-b2dc-46a4-82cb-ce298443559d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-8aab7e62ac47>:77: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start\n"
          ]
        }
      ],
      "source": [
        "#학습 파라미터 설정\n",
        "\n",
        "learning_rate = 3e-5\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "epoch = 20\n",
        "Sneg = -1e18\n",
        "\n",
        "# 학습\n",
        "\n",
        "print(\"start\")\n",
        "for epoch in range(epoch):  # 반복 횟수 변수인 epoch가 정의되어야 합니다.\n",
        "    for batch_idx, samples in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids, mask, label = samples\n",
        "        token_ids = token_ids.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "        mask = mask.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "        label = label.to(device)  # 입력 데이터를 GPU로 보냅니다.\n",
        "        out = model(token_ids)\n",
        "        out = out.logits\n",
        "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
        "        loss = criterion(mask_out.transpose(2, 1), label)\n",
        "        avg_loss = loss.sum() / mask.sum()\n",
        "        avg_loss.backward()\n",
        "        optimizer.step()\n",
        "print(\"end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeeNY4cc9LEp"
      },
      "outputs": [],
      "source": [
        "# print(\"start\")\n",
        "# for epoch in range(epoch):\n",
        "#     # tqdm을 사용하여 에포크 진행 상황을 실시간으로 확인\n",
        "#     epoch_iterator = tqdm(train_dataloader, desc=\"Epoch {}\".format(epoch + 1), ncols=100)\n",
        "#     for batch_idx, samples in enumerate(epoch_iterator):\n",
        "#         optimizer.zero_grad()\n",
        "#         token_ids, mask, label = samples\n",
        "#         token_ids = token_ids.to(device)\n",
        "#         mask = mask.to(device)\n",
        "#         label = label.to(device)\n",
        "#         out = model(token_ids)\n",
        "#         out = out.logits\n",
        "#         mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "#         mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
        "#         loss = criterion(mask_out.transpose(2, 1), label)\n",
        "#         avg_loss = loss.sum() / mask.sum()\n",
        "#         avg_loss.backward()\n",
        "#         optimizer.step()\n",
        "# print(\"end\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gK8x0osYjf4"
      },
      "source": [
        "대화 예시 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqjXxHBhYcwf"
      },
      "outputs": [],
      "source": [
        "#대화 예시 추출하기\n",
        "\n",
        "with torch.no_grad():\n",
        "    while 1:\n",
        "        kogpt2_utterance = input(\"user > \").strip()\n",
        "        if kogpt2_utterance == \"quit\":\n",
        "            break\n",
        "        kogpt2_response = \"\"\n",
        "        while 1:\n",
        "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ kogpt2_utterance + \"<unused1>\" + \"<sys>\" + kogpt2_response)).unsqueeze(dim=0).to(device)\n",
        "            pred = model(input_ids)\n",
        "            pred = pred.logits\n",
        "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "            if gen == \"</s>\":\n",
        "                break\n",
        "            kogpt2_response += gen.replace(\"▁\", \" \")\n",
        "            if \"00\" in kogpt2_response:\n",
        "              pass\n",
        "        print(\"Chatbot > {}\".format(kogpt2_response.strip()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgTbk4k_ZgoA"
      },
      "source": [
        "# **KoBERT**\n",
        "\n",
        "\n",
        "*   학습은 corpus로 진행하기\n",
        "*   입력은 KoGPT2의 답변으로 하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwHFu_fBZ47F"
      },
      "source": [
        "필요한 모듈 설치 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNY3h5K3Z2Jf"
      },
      "outputs": [],
      "source": [
        "#모듈 실행\n",
        "\n",
        "import gluonnlp as nlp\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFIZb-QfaSPK"
      },
      "source": [
        "cpu 확인 및 토크나이저/모델/보캡 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boI2GJqFaR2j"
      },
      "outputs": [],
      "source": [
        "#cpu 여부 확인\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "\n",
        "#토크나이저/모델/보캡 설정\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7D8WIXpadcu"
      },
      "source": [
        "데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ-TiwvAajYp"
      },
      "outputs": [],
      "source": [
        "#emotion과 시스템문장만 불러오기\n",
        "\n",
        "corpus_emotion_training = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training.csv\")\n",
        "\n",
        "#corpus의 1,2,3 나눠서 csv 저장하기\n",
        "\n",
        "corpus_emotion_training1 = corpus_emotion_training[['감정_대분류', '시스템문장1']]\n",
        "corpus_emotion_training1.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion1.csv\")\n",
        "corpus_emotion_training2 = corpus_emotion_training[['감정_대분류', '시스템문장2']]\n",
        "corpus_emotion_training2.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion2.csv\")\n",
        "corpus_emotion_training3 = corpus_emotion_training[['감정_대분류', '시스템문장3']]\n",
        "corpus_emotion_training3.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion3.csv\")\n",
        "\n",
        "\n",
        "#corpus 3개 모두 불러와서 먼저 합치기, 열 이름 바꾸기, dropna\n",
        "corpus_emotion_training1 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion1.csv\")\n",
        "corpus_emotion_training1.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_training1.rename(columns = {'시스템문장1' : 'response'}, inplace = True)\n",
        "corpus_emotion_training2 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion2.csv\")\n",
        "corpus_emotion_training2.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_training2.rename(columns = {'시스템문장2' : 'response'}, inplace = True)\n",
        "corpus_emotion_training3 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Training_emotion3.csv\")\n",
        "corpus_emotion_training3.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_training3.rename(columns = {'시스템문장3' : 'response'}, inplace = True)\n",
        "corpus_emotion_training = pd.concat([corpus_emotion_training1, corpus_emotion_training2, corpus_emotion_training3], axis = 0)\n",
        "corpus_emotion_training = corpus_emotion_training.dropna(axis=0)\n",
        "corpus_emotion_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8VfEOCZKeSN"
      },
      "outputs": [],
      "source": [
        "#emotion과 시스템문장만 불러오기\n",
        "\n",
        "corpus_emotion_validation = pd.read_excel(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation.xlsx\")\n",
        "\n",
        "#corpus의 1,2,3 나눠서 csv 저장하기\n",
        "\n",
        "corpus_emotion_validation1 = corpus_emotion_validation[['감정_대분류', '시스템문장1']]\n",
        "corpus_emotion_validation1.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion1.csv\")\n",
        "corpus_emotion_validation2 = corpus_emotion_validation[['감정_대분류', '시스템문장2']]\n",
        "corpus_emotion_validation2.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion2.csv\")\n",
        "corpus_emotion_validation3 = corpus_emotion_validation[['감정_대분류', '시스템문장3']]\n",
        "corpus_emotion_validation3.to_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion3.csv\")\n",
        "\n",
        "\n",
        "#corpus 3개 모두 불러와서 먼저 합치기, 열 이름 바꾸기, dropna\n",
        "corpus_emotion_validation1 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion1.csv\")\n",
        "corpus_emotion_validation1.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_validation1.rename(columns = {'시스템문장1' : 'response'}, inplace = True)\n",
        "corpus_emotion_validation2 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion2.csv\")\n",
        "corpus_emotion_validation2.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_validation2.rename(columns = {'시스템문장2' : 'response'}, inplace = True)\n",
        "corpus_emotion_validation3 = pd.read_csv(\"/content/drive/MyDrive/study/EMOJI CODE/1.dataset/감성대화말뭉치(최종데이터)_Validation_emotion3.csv\")\n",
        "corpus_emotion_validation3.rename(columns = {'감정_대분류' : 'emotion'}, inplace = True)\n",
        "corpus_emotion_validation3.rename(columns = {'시스템문장3' : 'response'}, inplace = True)\n",
        "corpus_emotion_validation = pd.concat([corpus_emotion_validation1, corpus_emotion_validation2, corpus_emotion_validation3], axis = 0)\n",
        "corpus_emotion_validation = corpus_emotion_validation.dropna(axis=0)\n",
        "corpus_emotion_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeZQsXCCL4pj"
      },
      "outputs": [],
      "source": [
        "corpus_emotion = pd.concat([corpus_emotion_training, corpus_emotion_validation], axis = 0)\n",
        "corpus_emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYsxKnceMBix"
      },
      "outputs": [],
      "source": [
        "corpus_emotion['emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_XZAdgiIIXx"
      },
      "outputs": [],
      "source": [
        "# #비율 동일하게 하기 위해 아래 코드 진행\n",
        "\n",
        "# # 불안, 분노, 상처, 슬픔, 당황, 기쁨 각각 15000개씩 랜덤하게 추출합니다.\n",
        "# sample_size = 20000\n",
        "\n",
        "# # 랜덤 시드를 설정하여 재현 가능한 결과를 얻습니다.\n",
        "# random.seed(42)\n",
        "\n",
        "# # 불안, 분노, 상처, 슬픔, 당황, 기쁨 각각 15000개씩 랜덤하게 추출합니다.\n",
        "# extracted_data = pd.concat([\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '불안'].sample(sample_size),\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '분노'].sample(sample_size),\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '상처'].sample(sample_size),\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '슬픔'].sample(sample_size),\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '당황'].sample(sample_size),\n",
        "#     corpus_emotion[corpus_emotion['emotion'] == '기쁨'].sample(sample_size)\n",
        "# ], ignore_index=True)\n",
        "\n",
        "# # 추출된 데이터를 셔플합니다.\n",
        "# extracted_data = extracted_data.sample(frac=1, random_state=42)\n",
        "\n",
        "# # 추출된 데이터를 확인합니다.\n",
        "# print(extracted_data['emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9NG0EbQ9Qr5"
      },
      "outputs": [],
      "source": [
        "# 불안, 분노, 상처, 슬픔, 당황, 기쁨 각각 15000개씩 랜덤하게 추출합니다.\n",
        "\n",
        "extracted_data = pd.concat([\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '불안'].sample(sample_size),\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '분노'].sample(sample_size),\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '상처'].sample(sample_size),\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '슬픔'].sample(sample_size),\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '당황'].sample(sample_size),\n",
        "    corpus_emotion[corpus_emotion['emotion'] == '기쁨'].sample(sample_size)\n",
        "], ignore_index=True)\n",
        "\n",
        "# 추출된 데이터를 셔플합니다.\n",
        "extracted_data = extracted_data.sample(frac=1, random_state=42)\n",
        "\n",
        "# 추출된 데이터를 확인합니다.\n",
        "print(extracted_data['emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gk23dzGM8Qi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 추출된 데이터를 8:2 비율로 훈련 데이터와 테스트 데이터로 나눕니다.\n",
        "train_ratio = 0.8  # 8:2 비율을 나타내는 비율\n",
        "test_ratio = 1.0 - train_ratio  # 테스트 데이터 비율\n",
        "\n",
        "# 각각의 감정에 대한 인덱스를 추출합니다.\n",
        "indices_불안 = corpus_emotion[corpus_emotion['emotion'] == '불안'].index\n",
        "indices_분노 = corpus_emotion[corpus_emotion['emotion'] == '분노'].index\n",
        "indices_상처 = corpus_emotion[corpus_emotion['emotion'] == '상처'].index\n",
        "indices_슬픔 = corpus_emotion[corpus_emotion['emotion'] == '슬픔'].index\n",
        "indices_당황 = corpus_emotion[corpus_emotion['emotion'] == '당황'].index\n",
        "indices_기쁨 = corpus_emotion[corpus_emotion['emotion'] == '기쁨'].index\n",
        "\n",
        "# 각각의 감정에 대한 훈련 및 테스트 인덱스를 생성합니다.\n",
        "train_indices_불안, test_indices_불안 = train_test_split(indices_불안, test_size=test_ratio, random_state=42)\n",
        "train_indices_분노, test_indices_분노 = train_test_split(indices_분노, test_size=test_ratio, random_state=42)\n",
        "train_indices_상처, test_indices_상처 = train_test_split(indices_상처, test_size=test_ratio, random_state=42)\n",
        "train_indices_슬픔, test_indices_슬픔 = train_test_split(indices_슬픔, test_size=test_ratio, random_state=42)\n",
        "train_indices_당황, test_indices_당황 = train_test_split(indices_당황, test_size=test_ratio, random_state=42)\n",
        "train_indices_기쁨, test_indices_기쁨 = train_test_split(indices_기쁨, test_size=test_ratio, random_state=42)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터를 인덱스를 기반으로 추출합니다.\n",
        "dataset_train = pd.concat([corpus_emotion.loc[train_indices_불안],\n",
        "                        corpus_emotion.loc[train_indices_분노],\n",
        "                        corpus_emotion.loc[train_indices_상처],\n",
        "                        corpus_emotion.loc[train_indices_슬픔],\n",
        "                        corpus_emotion.loc[train_indices_당황],\n",
        "                        corpus_emotion.loc[train_indices_기쁨]], ignore_index=True)\n",
        "\n",
        "dataset_test = pd.concat([corpus_emotion.loc[test_indices_불안],\n",
        "                       corpus_emotion.loc[test_indices_분노],\n",
        "                       corpus_emotion.loc[test_indices_상처],\n",
        "                       corpus_emotion.loc[test_indices_슬픔],\n",
        "                       corpus_emotion.loc[test_indices_당황],\n",
        "                       corpus_emotion.loc[test_indices_기쁨]], ignore_index=True)\n",
        "\n",
        "# 추출된 데이터를 셔플합니다.\n",
        "dataset_train = dataset_train.sample(frac=1, random_state=42)\n",
        "dataset_test = dataset_test.sample(frac=1, random_state=42)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터의 감정 비율을 확인합니다.\n",
        "print(\"훈련 데이터의 감정 비율:\")\n",
        "print(dataset_train['emotion'].value_counts())\n",
        "print(\"\\n테스트 데이터의 감정 비율:\")\n",
        "print(dataset_test['emotion'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdc-0JjqcL9r"
      },
      "source": [
        "emotion의 고유값 확인 후 라벨링, 리스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7TUQwY3cQYP"
      },
      "outputs": [],
      "source": [
        "# depressed_data.loc[(depressed_data['감정'] == \"지속되는우울한기분(우울감)\"), '감정'] = 0 와 같은 형태로 라벨링\n",
        "#'분노', '기쁨', '불안', '당황', '슬픔', '상처' (감성 말뭉치 기준)\n",
        "\n",
        "dataset_train.loc[(dataset_train['emotion'] == '분노'), 'emotion'] = 0\n",
        "dataset_train.loc[(dataset_train['emotion'] == '기쁨'), 'emotion'] = 1\n",
        "dataset_train.loc[(dataset_train['emotion'] == '불안'), 'emotion'] = 2\n",
        "dataset_train.loc[(dataset_train['emotion'] == '당황'), 'emotion'] = 3\n",
        "dataset_train.loc[(dataset_train['emotion'] == '슬픔'), 'emotion'] = 4\n",
        "dataset_train.loc[(dataset_train['emotion'] == '상처'), 'emotion'] = 5\n",
        "\n",
        "dataset_test.loc[(dataset_test['emotion'] == '분노'), 'emotion'] = 0\n",
        "dataset_test.loc[(dataset_test['emotion'] == '기쁨'), 'emotion'] = 1\n",
        "dataset_test.loc[(dataset_test['emotion'] == '불안'), 'emotion'] = 2\n",
        "dataset_test.loc[(dataset_test['emotion'] == '당황'), 'emotion'] = 3\n",
        "dataset_test.loc[(dataset_test['emotion'] == '슬픔'), 'emotion'] = 4\n",
        "dataset_test.loc[(dataset_test['emotion'] == '상처'), 'emotion'] = 5\n",
        "\n",
        "#리스트 생성\n",
        "\n",
        "dataset_train_list = []\n",
        "for ques1, label1 in zip(dataset_train['response'], dataset_train['emotion']):\n",
        "    data_item = []\n",
        "    data_item.append(ques1)\n",
        "    data_item.append(str(label1))\n",
        "    dataset_train_list.append(data_item)\n",
        "\n",
        "dataset_test_list = []\n",
        "for ques2, label2 in zip(dataset_test['response'], dataset_test['emotion']):\n",
        "    data_item = []\n",
        "    data_item.append(ques2)\n",
        "    data_item.append(str(label2))\n",
        "    dataset_test_list.append(data_item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MbnZ7p3-K97"
      },
      "outputs": [],
      "source": [
        "print(len(dataset_train_list))\n",
        "print(len(dataset_test_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdF_cHehc8F_"
      },
      "source": [
        "학습/테스트 데이터 나누기, 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU2kWZCQdB7Y"
      },
      "outputs": [],
      "source": [
        "#데이터 분할\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=34)\n",
        "dataset_train = dataset_train_list\n",
        "dataset_test = dataset_test_list\n",
        "\n",
        "#파라미터 설정\n",
        "\n",
        "max_len = 64\n",
        "batch_size = 128 #loss 줄이기 위해 높여보기\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 3 #5로 할 경우 런타임이 끊겨서 3으로 줄여봄\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5 #loss 줄이기 위해 낮춰보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pA1XnWUdMdH"
      },
      "source": [
        "클래스 정의하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM5m0EBLdNbU"
      },
      "outputs": [],
      "source": [
        "#bert 데이터셋 만드는 클래스 정의하기\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len, pad=True, pair=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.pad = pad\n",
        "        self.pair = pair\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.pair:\n",
        "            text = self.dataset[idx][0][0]\n",
        "            text_pair = self.dataset[idx][0][1]\n",
        "        else:\n",
        "            text = self.dataset[idx][0]\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            text_pair if self.pair else None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=self.pad,\n",
        "            truncation=False\n",
        "        )\n",
        "\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(inputs['input_ids']),\n",
        "            'attention_mask': torch.tensor(inputs['attention_mask']),\n",
        "            'token_type_ids': torch.tensor(inputs['token_type_ids'])\n",
        "        }\n",
        "\n",
        "        item['labels'] = int(self.dataset[idx][1])\n",
        "\n",
        "        # 패딩된 시퀀스/길이와 타입에 대한 내용/어텐션 마스크 시퀀스 세 가지 배열을 얻을 수 있도록 함\n",
        "        padded_seq = torch.tensor(inputs['input_ids']).numpy()\n",
        "        len_and_type = list(torch.tensor(inputs['token_type_ids']).shape) #dtype은 출력 안됨\n",
        "        attention_mask_seq = torch.tensor(inputs['attention_mask']).numpy()\n",
        "\n",
        "        return np.array(padded_seq), np.array(len_and_type), np.array(attention_mask_seq), item['labels']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = BERTDataset(dataset_train, tokenizer, max_len, True, True)\n",
        "test_dataset = BERTDataset(dataset_test, tokenizer, max_len, True, True)\n",
        "\n",
        "# 데이터로더 생성\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#학습 데이터셋 예시 추출해보기\n",
        "\n",
        "train_dataset[0]\n",
        "\n",
        "#bert 분류하는 클래스 정의하기\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=6,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "\n",
        "#모델 정의\n",
        "\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "# 아래 코드 해석 못함\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_loader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqJGlaWUdz4U"
      },
      "source": [
        "학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYuALxCvd08w"
      },
      "outputs": [],
      "source": [
        "train_history=[]\n",
        "test_history=[]\n",
        "loss_history=[]\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_loader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "        #print(label.shape,out.shape)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "            train_history.append(train_acc / (batch_id+1))\n",
        "            loss_history.append(loss.data.cpu().numpy())\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    #train_history.append(train_acc / (batch_id+1))\n",
        "\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_loader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "    test_history.append(test_acc / (batch_id+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fXWT6ONd1qp"
      },
      "source": [
        "아래 부분에서 input을 kogpt2의 답변으로 받아오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQcSwiBswdLt"
      },
      "outputs": [],
      "source": [
        "# #아래에서 필요한 e2v\n",
        "\n",
        "# import gensim.models as gsm\n",
        "\n",
        "# e2v = gsm.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/study/EMOJI CODE/1.dataset/emoji2vec/pre-trained/emoji2vec.bin', binary=True)\n",
        "\n",
        "# #이모지 함수 정의\n",
        "# #'분노', '기쁨', '불안', '당황', '슬픔', '상처' (감성 말뭉치 기준)\n",
        "\n",
        "# def emoticon(response, emoticon_name):\n",
        "#     emoticon_label = {\n",
        "#         'angry': ['😡', '😠', '🤬'],\n",
        "#         'happy': ['😄', '😃', '😁'],\n",
        "#         'unstable': ['😵', '😨', '😰'],\n",
        "#         'embarrassed': ['😳', '😅', '🙈'],\n",
        "#         'sad': ['😢', '😞', '😔'],\n",
        "#         'wounded': ['😫', '😩', '😣'],\n",
        "#     }  # 이모티콘 리스트 추가 예정\n",
        "#     all_emoticon = emoticon_label.get(emoticon_name, [])  # 모든 이모티콘을 저장할 리스트\n",
        "#     # 주어진 이모티콘 이름에 해당하는 이모티콘 리스트를 all_emoticon에 추가\n",
        "#     if all_emoticon:\n",
        "#         response_with_emoticon = f\"{response} {' '.join(all_emoticon)}\"\n",
        "#     else:\n",
        "#         response_with_emoticon = response\n",
        "\n",
        "#     return response_with_emoticon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPSJI_5x4wHE"
      },
      "outputs": [],
      "source": [
        "emoticon_label = {\n",
        "    'angry': ['😡', '😠', '🤬'],\n",
        "    'happy': ['😄', '😃', '😁'],\n",
        "    'anxious': ['😵', '😨', '😰'],\n",
        "    'embarrassed': ['😳', '😅', '🙈'],\n",
        "    'sad': ['😢', '😞', '😔'],\n",
        "    'hurted': ['😫', '😩', '😣']\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUdqihdP40Dd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def get_random_emoticon(emoticon_name):\n",
        "  emoticons = emoticon_label.get(emoticon_name, [])\n",
        "  if emoticons:\n",
        "    random_emoticon = random.choice(emoticons)\n",
        "    return random_emoticon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-gpdTZyd-E2"
      },
      "outputs": [],
      "source": [
        "#감정 예측하는 함수 정의\n",
        "\n",
        "def predict(predict_sentence):\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset(dataset_another, tokenizer, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length = valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "        test_eval = []\n",
        "        for i in out:\n",
        "            logits = i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "            #분노 기쁨 슬픔만 진행하는 것도 고려해보기\n",
        "            #에크만 참고해서 7가지로 분류\n",
        "            if np.argmax(logits) == 0:\n",
        "                # emotion = \"분노가\"\n",
        "                emoticon_name = \"angry\"\n",
        "            elif np.argmax(logits) == 1:\n",
        "                # emotion = \"기쁨이\"\n",
        "                emoticon_name = \"happy\"\n",
        "            elif np.argmax(logits) == 2:\n",
        "                # emotion = \"불안이\"\n",
        "                emoticon_name = \"anxious\"\n",
        "            elif np.argmax(logits) == 3:\n",
        "                # emotion = \"당황이\"\n",
        "                emoticon_name = \"embarrassed\"\n",
        "            elif np.argmax(logits) == 4:\n",
        "                # emotion = \"슬픔이\"\n",
        "                emoticon_name = \"sad\"\n",
        "            elif np.argmax(logits) == 5:\n",
        "                # emotion = \"상처가\"\n",
        "                emoticon_name = \"hurted\"\n",
        "\n",
        "            # angry에 해당하는 이모티콘 중 하나를 랜덤으로 추출\n",
        "            emoticon_choice = get_random_emoticon(emoticon_name)\n",
        "\n",
        "            # response_with_emoticon = emoticon_choice  # 이모티콘과 감정 이름을 함께 출력\n",
        "            print(\"Chatbot > \" + sentence + \"{}\".format(emoticon_choice)) #sentence를 conversation으로 변경하여 conversation = input/ sentence 구분하기?\n",
        "\n",
        "#입력 및 감정 분류된 것 출력\n",
        "\n",
        "end = 1\n",
        "while end == 1 :\n",
        "  # kogpt2_utterance = input(\"user > \").strip()\n",
        "    sentence = input(\"KoGPT2의 답변을 입력해주세요.: \") #kogpt2의 답변 넣는 코드로 수정\n",
        "    if sentence == 0 :\n",
        "        break\n",
        "    predict(sentence)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# end = 1\n",
        "# while end == 1 :\n",
        "#     user_utterance = input(\"user > \").strip()\n",
        "#     kogpt2_response = \"\"\n",
        "#     while True:\n",
        "#       input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ kogpt2_utterance + \"<unused1>\" + \"<sys>\" + kogpt2_response)).unsqueeze(dim=0).to(device)\n",
        "#       pred = model(input_ids)\n",
        "#       pred = pred.logits\n",
        "#       gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "#       if gen == \"</s>\":\n",
        "#           break\n",
        "#       kogpt2_response += gen.replace(\"▁\", \" \")\n",
        "#       predict(kogpt2_response) #시도\n",
        "#       print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7Hl2Rsp11IQ"
      },
      "outputs": [],
      "source": [
        "#kogpt2 다시\n",
        "\n",
        "#실행 토크나이저/모델 설정\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n",
        "koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n",
        "            pad_token=PAD, mask_token=MASK)\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "\n",
        "#cpu인지 아닌지 확인하는 코드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# #아래 코드 해석 못함\n",
        "# model.to(device)\n",
        "# model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Idr9WYoxAQxF"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    while True:\n",
        "        kogpt2_utterance = input(\"user > \").strip()\n",
        "        if kogpt2_utterance == \"quit\":\n",
        "            break\n",
        "        kogpt2_response = \"\"\n",
        "        while True:\n",
        "            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(\"<usr>\"+ kogpt2_utterance + \"<unused1>\" + \"<sys>\" + kogpt2_response)).unsqueeze(dim=0).to(device)\n",
        "            pred = model(input_ids)\n",
        "            pred = pred.logits\n",
        "            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "            if gen == \"</s>\":\n",
        "                break\n",
        "            kogpt2_response += gen.replace(\"▁\", \" \")\n",
        "            if \"00\" in kogpt2_response:\n",
        "                pass\n",
        "\n",
        "        # 감정 예측 및 이모지 추가된 답변 출력\n",
        "        predict_sentence = emoticon(kogpt2_response, emoticon_name)\n",
        "        predict(predict_sentence)\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GPgNmi5a_wO"
      },
      "outputs": [],
      "source": []
    }
  ]
}